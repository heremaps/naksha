# Shared configurations, include via:
# include_if_exists = '/home/postgres/common.conf'

listen_addresses = '0.0.0.0'                    # what IP address(es) to listen on;
                                                # comma-separated list of addresses;
                                                # defaults to 'localhost'; use '*' for all
                                                # (change requires restart)
port = 5432				                              # (change requires restart)


log_destination = 'stderr'                      # Valid values are combinations of
                          					            # stderr, csvlog, jsonlog, syslog, and
                          					            # eventlog, depending on platform.
                          					            # csvlog and jsonlog require
                          					            # logging_collector to be on.
logging_collector = on
log_directory = 'log'			                      # directory where log files are written, can be absolute or relative to PGDATA
log_filename = 'postgresql-%Y-%m-%d.log'	      # log file name pattern, can include strftime() escapes
log_file_mode = 0640			                      # creation mode for log files,
log_rotation_age = 1d			                      # Automatic rotation of logfiles will happen after that time. 0 disables.
log_rotation_size = 1GB		                      # Automatic rotation of logfiles will happen after that much log output. 0 disables.
log_truncate_on_rotation = off		              # If on, an existing log file with the
                                                # same name as the new log file will be
                                                # truncated rather than appended to.
                                                # But such truncation only occurs on
                                                # time-driven rotation, not on restarts
                                                # or size-driven rotation. Default is
                                                # off, meaning append to existing files
                                                # in all cases.

#debug_print_parse = off
#debug_print_rewritten = off
#debug_print_plan = off
#debug_pretty_print = on
log_autovacuum_min_duration = 10000	            # log autovacuum activity;
                                                # -1 disables, 0 logs all actions and
                                                # their durations, > 0 logs only
                                                # actions running at least this number
                                                # of milliseconds.
log_checkpoints = on
log_connections = on
log_disconnections = on
#log_duration = off
#log_error_verbosity = default		# terse, default, or verbose messages
#log_hostname = off
#log_line_prefix = '%m [%p] '		# special values:
					#   %a = application name
					#   %u = user name
					#   %d = database name
					#   %r = remote host and port
					#   %h = remote host
					#   %b = backend type
					#   %p = process ID
					#   %P = process ID of parallel group leader
					#   %t = timestamp without milliseconds
					#   %m = timestamp with milliseconds
					#   %n = timestamp with milliseconds (as a Unix epoch)
					#   %Q = query ID (0 if none or not computed)
					#   %i = command tag
					#   %e = SQL state
					#   %c = session ID
					#   %l = session line number
					#   %s = session start timestamp
					#   %v = virtual transaction ID
					#   %x = transaction ID (0 if none)
					#   %q = stop here in non-session
					#        processes
					#   %% = '%'
					# e.g. '<%u%%%d> '
#log_lock_waits = off			# log lock waits >= deadlock_timeout
#log_recovery_conflict_waits = off	# log standby recovery conflict waits
					# >= deadlock_timeout
#log_parameter_max_length = -1		# when logging statements, limit logged
					# bind-parameter values to N bytes;
					# -1 means print in full, 0 disables
#log_parameter_max_length_on_error = 0	# when logging an error, limit logged
					# bind-parameter values to N bytes;
					# -1 means print in full, 0 disables
log_statement = 'none'			# none, ddl, mod, all
#log_replication_commands = off
#log_temp_files = -1			# log temporary files equal or larger
                          # than the specified size in kilobytes;
                          # -1 disables, 0 logs all temp files
log_timezone = UTC


temp_tablespaces = 'temp'			# a list of tablespace names, '' uses
					                    # only default tablespace
default_transaction_isolation = 'read committed' # 'read committed'
             # 'read uncommitted', 'read committed', 'repeatable read', or 'serializable'
default_transaction_read_only = off
# SET TRANSACTION READ WRITE
# https://www.postgresql.org/docs/current/sql-set-transaction.html

random_page_cost = 1.1
cpu_tuple_cost = 0.03
cpu_index_tuple_cost = 0.0005
huge_pages = try
idle_in_transaction_session_timeout = 60000
shared_preload_libraries = 'pg_partman_bgw'
# session_preload_libraries =

datestyle = 'iso, mdy'
lc_messages = 'C.UTF-8'			# locale for system error message
lc_monetary = 'C.UTF-8'			# locale for monetary formatting
lc_numeric = 'C.UTF-8'			# locale for number formatting
lc_time = 'C.UTF-8'				  # locale for time formatting

# pg_partman
# pg_partman_bgw.interval = 3600
# pg_partman_bgw.role = 'postgres'
# pg_partman_bgw.dbname = 'keith'

# r6idn.metal

# Memory/Disk
max_connections = 1024
shared_buffers = 4GB
maintenance_work_mem = 1GB
default_statistics_target = 10000   # Sets the default statistics target, 1 to 10000
work_mem = 256MB
dynamic_shared_memory_type = posix	# the default is usually the first option

# WAL
# To change WAL segment size on existing system, do:
# pg_resetwal -D "$PGDATA" --wal-segsize 1GB
wal_level = minimal
wal_compression = lz4    # off, pglz, lz4 (--with-zstd) or zstd (--with-zstd)
full_page_writes = off   # When this parameter is on, the PostgreSQL server writes the entire content
                         # of each disk page to WAL during the first modification of that page after a
                         # checkpoint.
                         # This option assumes that there are none atomic writes, so that partial
                         # writes of a row is possible. However, we aligned the chunk-size (strip-size)
                         # with the row size and that makes is close to impossible to get partial writes
                         # for our EBS volumes. The impact of this setting with our high frequency of
                         # WAL log writes makes it by far to expensive, especially taking into consideration
                         # that we anyway have backups as snapshots on daily base.
#wal_segment_size = 1GB #  The total size of a WAL segment file in bytes (defined in initdb).
wal_buffers = 1GB # The amount of shared memory used for WAL data that has not yet been written to disk (max wal_segment_size).
min_wal_size = 2GB # Minimum WAL size, at least two times wal_segment_size
max_wal_size = 16GB # Maximum WAL size, at least min_wal_size
                      # xlog is started when (max_wal_size / (2 + checkpoint_completion_target)) hit
                      # see: https://github.com/postgres/postgres/blob/REL_16_STABLE/src/backend/access/transam/xlog.c#L1947
                      # #define ConvertToXSegs(x, segsize)	XLogMBVarToSegs((x), (segsize))
                      # ...
                      # static void CalculateCheckpointSegments(void) {
                      # target = (double) ConvertToXSegs(max_wal_size_mb, wal_segment_size) / (1.0 + CheckPointCompletionTarget);
                      # In a nutshell:
                      #     max_wal_size / (1 + checkpoint_completion_target), so around 50% of max_wal_size
                      # This means, to ensure that we do not trigger xlog too early we need to delay it until
                      # the last moment, which is for max_wal_size = (shared_buffers * 1.5), resulting in xlog
                      # starting at (shared_buffers * 0.75)
                      # In our case, xlog we be trigger after around 384gb have been written
                      # (if network is 100% utilized, after around 16 to 20 seconds, roughly)
wal_keep_size = 0 # We do not have replicas
max_wal_senders = 0 # default is 10, prevents to set WAL to minimal
# A checkpoint moves WAL log forward and writes dirty pages.
# We want to write at least 90% of dirty shared_buffers in the checkpoint timeout
# We have 100Gbps EBS bandwidth and 200Gbps network, so theoretically, we can collect 25gb/s of dirty pages
# Assuming we want to bulk load 100 million features with 300gb (around 3kb/feature)
# - We want it to be loaded at ones and then later being written down to EBS
# - We can write 12.5gb/s to WAL and keep all dirty pages in memory
# - It will take only 24 seconds to be loaded, sp 60s is totally long enough, even for slower clients
# Assuming we need to write WAL logs and dirty pages, we have only have 50% of throughput, 6.25gb/s
# - With 6.25gb/s we can write 187.5gb in 30 seconds
checkpoint_completion_target = 0.9
checkpoint_timeout = 60s
# wal-writer runs only when synchronous_commit=off
wal_writer_delay = 1000
wal_writer_flush_after = 1GB
# Write dirty pages in background, reduces load to WAL writer.
# Normally, write 2 times the pages that have been newly allocated up to max-pages.
#bgwriter_delay = 1000ms
#bgwriter_lru_multiplier = 2
bgwriter_lru_maxpages = 0 # Disable background writer, we use only checkpoints, but these more frequently
#bgwriter_flush_after = 0
# disable explicit flush, OS shall do by itself
# write-throughput = (32*320000)/1000 = 10240 mb/s
# total pages = 256*2^30/32,000 = 8,388,608
# write-throughput = ({page-size}*{bgwriter_lru_maxpages})/{bgwriter_delay} = around mb/s
# total pages = {shared_buffers in GiB}*2^20/{page-size}

# Concurrency
effective_io_concurrency = 1000 # We expect always SSD
max_worker_processes = 256
max_parallel_workers = 256
max_parallel_workers_per_gather = 16
max_parallel_maintenance_workers = 4
archive_mode = off

# Planner cost
effective_cache_size = 896GB    # Sets the planner's assumption about the total size of the data caches
seq_page_cost = 1.0000			    # Sets the planner's estimate of the cost of a sequentially fetched disk page
random_page_cost = 1.0500			  # Sets the planner's estimate of the cost of a non sequentially fetched disk page
cpu_tuple_cost = 0.0100			    # Sets the planner's estimate of the cost of processing each tuple
cpu_index_tuple_cost = 0.0001		# Sets the planner's estimate of the cost of processing each index entry during an index scan
                                # 1/100'th of cpu_tuple_cost, we want index to be used always
cpu_operator_cost = 0.0025		  # Sets the planner's estimate of the cost of processing each operator or function call
parallel_setup_cost = 100.0	    # Sets the planner's estimate of the cost of starting up worker processes for parallel query
parallel_tuple_cost = 0.0100	  # Sets the planner's estimate of the cost of passing each tuple (row) from worker to leader backend
min_parallel_table_scan_size = 1MB
min_parallel_index_scan_size = 1kB

# - Genetic Query Optimizer -

#geqo = on
#geqo_threshold = 12
#geqo_effort = 5			# range 1-10
#geqo_pool_size = 0			# selects default based on effort
#geqo_generations = 0			# selects default based on effort
#geqo_selection_bias = 2.0		# range 1.5-2.0
#geqo_seed = 0.0			# range 0.0-1.0

# - Other Planner Options -

#default_statistics_target = 100	# range 1-10000
#constraint_exclusion = partition	# on, off, or partition
#cursor_tuple_fraction = 0.1		# range 0.0-1.0
#from_collapse_limit = 8
jit = off				# allow JIT compilation
#join_collapse_limit = 8		# 1 disables collapsing of explicit
					# JOIN clauses
#plan_cache_mode = auto			# auto, force_generic_plan or
					# force_custom_plan
#recursive_worktable_factor = 10.0	# range 0.001-1000000

row_security = off
#default_table_access_method = 'heap'
#default_tablespace = ''		        # a tablespace name, '' uses the default
default_toast_compression = 'lz4'	  # 'pglz' or 'lz4'
temp_tablespaces = 'temp'			      # a list of tablespace names, '' uses
					                          # only default tablespace
#check_function_bodies = on
default_transaction_isolation = 'read committed' # serializable, repeatable read, read committed, read uncommitted
#default_transaction_read_only = off
#default_transaction_deferrable = off
#session_replication_role = 'origin'
statement_timeout = 5min			              # in milliseconds, 0 is disabled
                                            # Abort any statement that takes more than the specified amount of time.
lock_timeout = 10s			                    # in milliseconds, 0 is disabled
idle_in_transaction_session_timeout = 60s   # in milliseconds, 0 is disabled
                                            # Sets the maximum allowed idle time between queries, when in a transaction
                                            # Terminate any session that has been idle (that is, waiting for a client query)
                                            # within an open transaction for longer than the specified amount of time.
idle_session_timeout = 15min                # in milliseconds, 0 is disabled
                                            # Sets the maximum allowed idle time between queries, when not in a transaction
                                            # Terminate any session that has been idle (that is, waiting for a client query),
                                            # but not within an open transaction, for longer than the specified amount of time.
                                            # If this value is specified without units, it is taken as milliseconds.
gin_pending_list_limit = 16MB               # Sets the maximum size of a GIN index's pending list, which is used when fastupdate
                                            # is enabled. If the list grows larger than this maximum size, it is cleaned up by
                                            # moving the entries in it to the index's main GIN data structure in bulk.
#createrole_self_grant = ''		# set and/or inherit

#------------------------------------------------------------------------------
# STATISTICS
#------------------------------------------------------------------------------

# - Cumulative Query and Index Statistics -

track_activities = on                 # Collects information about executing commands (default=on)
track_activity_query_size = 1MB	      # Sets the size reserved for pg_stat_activity.query, in bytes (max 1mb)
track_counts = on                     # Collects statistics on database activity (default=on)
                                      # Required for autovacuum!
track_io_timing = on                  # Collects timing statistics for database I/O activity (default=off)
track_wal_io_timing = on              # Collects timing statistics for WAL I/O activity (default=off)
track_functions = pl			            # none, pl, all (default=none)
                                      # Collects function-level statistics on database activity
stats_fetch_consistency = none	      # cache, none, snapshot (default=cache)
                                      # Sets the consistency of accesses to statistics data
                                      # When set to none, each access re-fetches counters from shared memory.
                                      # When set to cache, the first access to statistics for an object caches
                                      # those statistics until the end of the transaction unless
                                      # pg_stat_clear_snapshot() is called. When set to snapshot, the first
                                      # statistics access caches all statistics accessible in the current database,
                                      # until the end of the transaction unless pg_stat_clear_snapshot() is called.


# - Monitoring -

compute_query_id = auto               # Enables in-core computation of a query identifier. Query identifiers can
                                      # be displayed in the pg_stat_activity view, using EXPLAIN, or emitted in
                                      # the log if configured via the log_line_prefix parameter.
# All are by default off
log_statement_stats = off             # Writes cumulative performance statistics to the server log
log_parser_stats = off                # Writes parser performance statistics to the server log
log_planner_stats = off               # Writes planner performance statistics to the server log
log_executor_stats = off              # Writes executor performance statistics to the server log

#------------------------------------------------------------------------------
# [AUTO]VACUUM
#------------------------------------------------------------------------------
autovacuum = on			                          # Enable autovacuum subprocess?  'on'
					                                    # requires track_counts to also be on.
autovacuum_max_workers = 4		                # max number of autovacuum subprocesses
autovacuum_naptime = 10s		                  # time between autovacuum runs
autovacuum_vacuum_threshold = 10000	          # min number of row updates before vacuum
autovacuum_vacuum_insert_threshold = 10000	  # min number of row inserts before vacuum; -1 disables insert vacuums
autovacuum_analyze_threshold = 10000	        # min number of row updates before analyze
autovacuum_vacuum_scale_factor = 0.1	        # fraction of table size before vacuum
autovacuum_vacuum_insert_scale_factor = 0.2	  # fraction of inserts over table size before insert vacuum
autovacuum_analyze_scale_factor = 0.1         # fraction of table size before analyze
autovacuum_freeze_max_age = 1000000000	      # maximum XID age before forced vacuum (default: 200000000)
                                              # select max(age(datfrozenxid)) from pg_database;
autovacuum_multixact_freeze_max_age = 1500000000 # maximum multixact age before forced vacuum (default: 400000000)
                                              # SELECT relname, age(relfrozenxid) as xid_age, pg_size_pretty(pg_table_size(oid)) as table_size
                                              # FROM pg_class WHERE relkind = 'r' and pg_table_size(oid) > 1073741824
                                              # ORDER BY age(relfrozenxid) DESC LIMIT 20;
autovacuum_vacuum_cost_delay = 0    	        # milliseconds; default vacuum cost delay for autovacuum, -1 means use vacuum_cost_delay					                                    #
autovacuum_vacuum_cost_limit = 1000	          # default vacuum cost limit for autovacuum, -1 means use vacuum_cost_limit
                                              # Vacuum cost amount available before napping, for autovacuum

# Vacuum
vacuum_freeze_min_age = 10000000              # Specifies the cutoff age (in transactions) that VACUUM should use to decide whether
                                              # to trigger freezing of pages that have an older XID. (default: 50000000)
vacuum_multixact_freeze_min_age = 10000000
vacuum_freeze_table_age = 800000000           # VACUUM performs an aggressive scan if the table's pg_class.relfrozenxid field has reached
                                              # the age specified by this setting. An aggressive scan differs from a regular VACUUM in
                                              # that it visits every page that might contain unfrozen XIDs or MXIDs, not just those that
                                              # might contain dead tuples.(default: 150000000)
                                              # Keep at around 80% of autovacuum_freeze_max_age
vacuum_multixact_freeze_table_age = 800000000
vacuum_cost_delay = 0                         # milliseconds; The amount of time that the process will sleep when the cost
                                              # limit has been exceeded. If this value is specified without units, it is
                                              # taken as milliseconds. The default value is zero, which disables the
                                              # cost-based vacuum delay feature. Positive values enable cost-based vacuuming.
vacuum_cost_limit = 1000                      # The accumulated cost that will cause the vacuuming process to sleep.
#vacuum_failsafe_age = 1600000000
#vacuum_multixact_failsafe_age = 1600000000


#------------------------------------------------------------------------------
# LOCK MANAGEMENT
#------------------------------------------------------------------------------

deadlock_timeout = 10s                      # This is the amount of time to wait on a lock before checking to see if there is
                                            # a deadlock condition. The check for deadlock is relatively expensive, so the
                                            # server doesn't run it every time it waits for a lock.
max_locks_per_transaction = 256		          # min 10
max_pred_locks_per_transaction = 256	      # min 10
max_pred_locks_per_relation = -2	          # negative values mean
					                                  # (max_pred_locks_per_transaction / -max_pred_locks_per_relation) - 1
max_pred_locks_per_page = 8                 # Sets the maximum number of predicate-locked tuples per page
                                            # This controls how many rows on a single page can be predicate-locked before the
                                            # lock is promoted to covering the whole page. The default is 2.
                                            # We increase the row size by 4 times (32k instead of 8k), so increase this too


# Other
synchronize_seqscans = off                  # This allows sequential scans of large tables to synchronize with each other, so
                                            # that concurrent scans read the same block at about the same time and hence share
                                            # the I/O workload.
                                            # This can result in unpredictable changes in the row ordering returned by queries
                                            # that have no ORDER BY clause. Setting this parameter to off ensures the pre-8.3
                                            # behavior in which a sequential scan always starts from the beginning of the table.
                                            # NOTE: We have enough cache (as well in the OS) so that for us order is more important!
transform_null_equals = on                  # Treats "expr=NULL" as "expr IS NULL"
                                            # default is off

hba_file = '/home/postgres/pg_hba.conf'
# include_if_exists 'r6idn.metal.conf'
